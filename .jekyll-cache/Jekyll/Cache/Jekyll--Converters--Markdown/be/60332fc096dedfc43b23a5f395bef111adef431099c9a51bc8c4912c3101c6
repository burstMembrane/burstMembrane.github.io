I"§0<h1 id="chapter-two">CHAPTER TWO</h1>
<h2 id="using-the-user-behavioural-quantification-and-surveillance-capitalism">Using the user: Behavioural Quantification and Surveillance Capitalism</h2>

<p><img src="images/thesis/image002.jpg" alt="fig 1" /></p>

<h3 id="fig-1-dynamic-video-data-aggregated-into-a-single-image-2019">Fig 1: Dynamic video data aggregated into a single image (2019)</h3>

<p>The widespread use of data extraction and collection by large corporations such as Google and Facebook as well as government surveillance agencies has led to an emerging form of capitalism defined as ‚ÄúSurveillance Capitalism‚Äù (Zuboff 2015, p.75). Surveillance is not anymore limited to closed circuit cameras networked to a remote TV screen in a darkened room. Instead huge de-centralized server networks store personal data generated by internet users and scrape it for insight into human behaviours of consumption. The platforms for sharing and connectedness developed by these corporations are in large part motivated by the pursuit of profit and advertising revenue. The old journalistic adage of ‚Äúthere is no such thing as a free lunch‚Äù applies wholly to the digital age. The free platforms on which social content is shared in fact contain elaborate and sophisticated advertising platforms run by algorithms hidden from the user. These algorithms create connections between content clicked and shared online by individual users as well as tracking a personal history of what has been clicked before. Through tracking cookies and JavaScript plugins, a database of the user‚Äôs patterns of behaviour across internet platforms can be created and populated with lucrative demographic information to be sold to advertisers. Thus, it is in the interest of large tech companies such as Google and Facebook to encourage users to create and share content, as well as engage with computing technologies in as many contexts as possible (Zuboff 2015, p.79). In many cases what once may have been authentic and distinctly human behaviour - exploring a place, connecting with friends and family, and seeking out information and knowledge about the world around us, is increasingly mediated by the platforms which make this possible online. The difference between the organic or human impulses which drive this behaviour and the tools which supposedly facilitate them is that the platforms have been created to encourage certain types of behaviour. Google autofills searches based on your history, very convenient but also an expression of determinism - what you wanted to find has been searched by other people beforehand, and can be quantified within a larger dataset of searches that occurred before you even thought to search (2015, p.83).  Facebook tags images with yours and other‚Äôs faces and curates your news feed with the content that an algorithm has determined is substantial to you. This creates a feedback loop between organic and suggested behaviour. For Zuboff, this is the work of large tech companies into the commodification and quantification of human behavioural patterns (2015, p. 82). The digital era marks a shift in the balance of power from those with ownership of the means of production to those ‚Äúwith the means of behavioural modification‚Äù (2015, p.82). These techniques of ‚Äòhuman hacking‚Äô can take many forms but they are in essence an attempt to exploit vulnerabilities and natural impulses in humanity in order to increase engagement with digital platforms. It is no coincidence that notifications on your smartphone initiate a dopamine rush, or that it is becoming harder to just watch one video on YouTube.</p>

<p>What was once a highly desirable engineering tactic is now being seen to have untold effects. For example, since 2019 Instagram has piloted a feature that hides likes from the platform; meaning users would need to choose to see how many likes an image or video has after seeing the content (Wong, 2019). This has sparked criticism about the mental health effects of ‚Äúvanity metrics‚Äù: the amount of likes and shares one receives for a given post. The false correlation of the value of a post with the amount of likes it gets is seen to be a psychologically damaging experience, especially for younger social media users (Wong, 2019). Importantly, with the increasing pervasiveness of these platforms into the social life of millions of people it becomes a lot harder to opt-out or find alternatives without becoming alienated from what forms a sizeable chunk of social communication in the digital era.</p>

<p><img src="images/thesis/image003.png" alt="fig 2" /></p>
<h3 id="fig-2-love-on-instagram-top-posts-jun-2019">Fig 2: #love on Instagram, top posts Jun 2019</h3>

<p>Steyerl (2013) argues that the Internet and its linked technologies have begun to move offline: meaning the effects of online behaviour are becoming profoundly intermingled with the reality of everyday life. The effect of this is a world where image and reality have formed a dependent relationship - a era where ‚Äúimage and world are in many cases just versions of each other‚Äù (Steyerl 2013, p.6). Steyerl updated her argument in a 2018 New York Times article, proposing that reality has now become the victim of ‚Äútechnological disruption‚Äù (Steyerl 2018); and that the once utopian vision of digital technologies as platforms for connection and information have instead become invasive technologies for identification and social-ranking via likes, clicks and hidden metrics.</p>

<p><img src="images/thesis/image005.png" alt="fig 3" /></p>
<h3 id="fig-3-still-from-instafeed-2019-scrolling-screen-capture-run-through-averaging-algorithm">Fig 3: Still from InstaFeed (2019), Scrolling screen capture run through averaging algorithm</h3>

<p>In his 2017 essay, ‚ÄúArt, Technology and Humanism‚Äù, Boris Groys investigated the link between Art, Technology and Commodification. Groys cites Heidegger‚Äôs idea that technology is essentially/primarily developed as a means of immunizing humanity from change or accident (Groys 2017, p.1). To achieve this, it is necessary to create technologies which store, quantify and make available resources (Groys 2017, p.2). The inevitable conclusion of quantification is that the ‚Äúhuman beings also begin to be regarded as a resource‚Äù in relation to that technology (Groys 2017, p.2). For example, during the Industrial Revolution artisans became factory workers; and, later, those factory workers became information workers as white-collar office jobs became the norm. For Heidegger, this creates a degrading condition where a person is commodified into a thing, largely, a piece of exploitable ‚Äúhuman capital‚Äù (2017, p.2).</p>

<p>For Groys, art is a more complex form of commodity. He points out that while most commodities are destroyed through the act of consumption, art is not (Groys 2017, p.2). Although artworks can also be consumed and used as tools for conveying meaning, they are free from a prerequisite of consumption/destruction and, instead, the consumption of art is amended by its contemplation (Groys 2017, p.2). To Groys, art as presented on the internet becomes a part of daily life. It is viewed as documentation of a ‚Äúreal working process taking place in the real, offline world‚Äù (2017, p.9). This narrow definition does not include art which is supposed to exist on the internet itself or which cannot be documented through images, text, video or sound in a consumable way. However, it seems obvious that on the internet the consumption of art takes place alongside social networking, communications, and practical activities as part of a user‚Äôs daily internet-life. As Groys notes ‚Äúthere are no walls in internet space‚Äù (2017, p.11), but there are definitely thin links which connect user activity online. Third-party advertising websites keep tabs on user activity which feed ‚Äòpersonalisation‚Äô algorithms. This means that the consumption of art is also linked to the same methods of data-surveillance which are used to track social and economic behaviour of individuals. 
For my Honours project I have created networked applications that seek to disrupt or expose the links between art seen on and offline. In Shibuya Threshold (2019), I hijacked a public Surveillance Camera and fed it through a thresholding and restructuring algorithm hosted on a remote server. The reformed image was then re-presented as a live feed, online, to which viewers received a link. This work is not simply a documentation of real-world activity viewed online: It is a work made from data found online and then hosted elsewhere ‚Äì essentially, a direct connection between the server hosting the camera feed, the server hosting the app, and the user‚Äôs computer.</p>

<p><img src="images/thesis/image007.png" alt="fig 4" /></p>
<h3 id="fig-4-shibuya-threshold-2019-live-video-feed-manipulated-by-thresholding-algorithm-accessed-11-june-2019">Fig 4: Shibuya Threshold (2019) Live video feed manipulated by thresholding algorithm accessed 11 June 2019.</h3>

<p>Data extraction and manipulation via thresholding and tracking algorithms has also been explored in other recent works. Using OpenCV, an open-source library initially developed by Intel, I investigated different methods of data extraction and quantification through computer vision. These methods are the aggregation of video frames, cropping and restructuring images using bounding boxes, and the storage and dissemination of artworks on remote servers. The major difference between my implementations and those of the dominant technology companies is that of intention, transparency, and indeterminacy.</p>

<p><img src="images/thesis/image009.png" alt="fig 5" /></p>
<h3 id="fig-5-still-from-factorybuyscomau-website-algorithm-suggests-products-for-consumption">Fig 5: Still from factorybuys.com.au website: algorithm suggests products for consumption.</h3>

<p>Firstly, my intention is not to profit from or accumulate data in order to advertise to users. My algorithm deliberately searches for data within image and sound which human beings would not find useful or valuable in any constructed way. Human subjects are fragmented and de-identified by the processing of the sound/image data. In one outcome, the informative content of the video and sound feed is broken up to the point of incomprehensibility. This encourages audiences to view the original data and its mediated form on the same plane. Secondly, my code is transparent and posted on GitHub under a Creative Commons license. Anyone who wishes to see how the data is being extracted and processed is free to download the code and try it out for themselves. Thirdly, the algorithm is indeterminate; it breaks up the data in a nonlinear or pseudo-random way, placing mediated and unmediated on the same plane of meaning. The algorithm is content-agnostic (and extensible). It attempts to organize all content in the same way, be it a YouTube video, a live surveillance feed, or a video produced by myself. To the algorithm, human behaviour and features are judged on their transitions from a contrast of brightness to darkness ‚Äî a feature of an arbitrary integer value rather than the content‚Äôs implied meaning.</p>

<p><img src="images/thesis/image012.jpg" alt="fig 6" /></p>
<h3 id="fig-6-study-in-thresholded-video-april-2019">Fig 6: Study in thresholded video, April 2019</h3>

<p><img src="images/thesis/image013.jpg" alt="fig 7" /></p>
<h3 id="fig-7-networked-mediation-2019-installation-view">Fig 7: Networked Mediation (2019), installation view</h3>

<p>My coding investigations are accompanied by work with the presentation of the computer as sculptural object. This includes foregrounding how the content is presented via the removal of certain important functional elements. This aims at explicitly undermining users‚Äô expectations of the computer interface. By removing the keyboard and mouse and automating certain network functions my aim is to encourage users to question their own expectations of agency and control with regards to such interfaces.  This agency, as shown by Zuboff and Barile, is largely illusory ‚Äî the freedom of choice in online behaviour is mediated by algorithms which attempt to quantify and automate human behaviour. My research addresses this by questioning the interface of the computer and the real level of control users have in their online and offline behaviour.</p>

:ET